{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a samll and big versions of toy example data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Simpson's Paradox\n",
    "- Create toy data where the paradox is evident\n",
    "- Fit a na√Øve regression where the relation is not intuitive\n",
    "- Then show what happens when a confounder is added (direction is changed)\n",
    "- Throwing all the variables in kind of works but specifying a causal DAG will get the estimates correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import rand, when, lit, col\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"ToyExamplePySpark\").getOrCreate()\n",
    "\n",
    "# Set random seed\n",
    "spark.sparkContext.setRandomSeed(853210)\n",
    "\n",
    "# Create a DataFrame with the desired number of samples\n",
    "n_samples = 2000\n",
    "df = spark.range(n_samples)\n",
    "\n",
    "# Generate toy data\n",
    "df = df.withColumn(\"Winter_Ind\", F.when(F.rand() < 0.24, 1).otherwise(0))\n",
    "\n",
    "df = df.withColumn(\"Rain_Ind\", \n",
    "                   F.when(F.rand() < (0.2 + col(\"Winter_Ind\") * 0.3), 1).otherwise(0))\n",
    "\n",
    "df = df.withColumn(\"Speed_KMpH\", \n",
    "                   F.randn() * 0.7 + (60 - col(\"Rain_Ind\") * 0.9))\n",
    "\n",
    "df = df.withColumn(\"Fuel_Consumption_LpKM\", \n",
    "                   F.randn() * 0.5 + (50 + col(\"Speed_KMpH\") / 4 + col(\"Rain_Ind\") * 2.1))\n",
    "\n",
    "# Select only the columns we need\n",
    "toy_example = df.select(\"Winter_Ind\", \"Rain_Ind\", \"Speed_KMpH\", \"Fuel_Consumption_LpKM\")\n",
    "\n",
    "# Show the first few rows\n",
    "toy_example.show(5)\n",
    "\n",
    "# Save toy_example as Parquet file locally\n",
    "toy_example.write.parquet(\"toy_example.parquet\")\n",
    "\n",
    "# To use the saved Parquet file later, you can read it like this:\n",
    "# loaded_toy_example = spark.read.parquet(\"toy_example.parquet\")\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
